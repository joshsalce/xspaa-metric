{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10698103,"sourceType":"datasetVersion","datasetId":6623893}],"dockerImageVersionId":30886,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport warnings\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nfrom sklearn.model_selection import KFold, cross_val_score\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\nimport optuna\nimport xgboost as xgb\nfrom xgboost import plot_importance\nfrom sklearn.model_selection import cross_val_score, KFold\nfrom sklearn.metrics import log_loss, brier_score_loss\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM, Dense, Masking, Dropout\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.models import load_model\n\npath = \"/kaggle/input/xspaa-data/\"\noutput_path = \"/kaggle/working/\"\n\nwarnings.filterwarnings(\"ignore\")\n\ntf.random.set_seed(909)\nnp.random.seed(909)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-09T01:58:22.109204Z","iopub.execute_input":"2025-02-09T01:58:22.109543Z","iopub.status.idle":"2025-02-09T01:58:42.337997Z","shell.execute_reply.started":"2025-02-09T01:58:22.109497Z","shell.execute_reply":"2025-02-09T01:58:42.336669Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/xspaa-data/test_set.csv\n/kaggle/input/xspaa-data/training_set.csv\n/kaggle/input/xspaa-data/points_data.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Read in Data\ntrain_data = pd.read_csv(path + \"training_set.csv\")\ntest_data = pd.read_csv(path + \"test_set.csv\")\npoints_data = pd.read_csv(path + \"points_data.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T01:58:42.338914Z","iopub.execute_input":"2025-02-09T01:58:42.339508Z","iopub.status.idle":"2025-02-09T01:58:42.374562Z","shell.execute_reply.started":"2025-02-09T01:58:42.339477Z","shell.execute_reply":"2025-02-09T01:58:42.373435Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Set X and y columns\nxgb_model_data_cols = ['stroke', 'type_of_shot', 'server_x', 'server_y', 'receiver_x', 'receiver_y']\n\ntrain_X = train_data[xgb_model_data_cols].astype({\"stroke\":'category', \"type_of_shot\":'category'}) \ntrain_y = train_data[\"ServerWinsPoint\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T01:58:42.375559Z","iopub.execute_input":"2025-02-09T01:58:42.376008Z","iopub.status.idle":"2025-02-09T01:58:42.401721Z","shell.execute_reply.started":"2025-02-09T01:58:42.375948Z","shell.execute_reply":"2025-02-09T01:58:42.400251Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"# Baseline","metadata":{}},{"cell_type":"code","source":"# Create a copy of test_data to maintain a baseline\nbaseline_test_data = test_data.copy()\n\n# Define the baseline prediction probability for server winning point\nbaseline_pred_proba = 0.642\n\ntest_rally_outcomes = baseline_test_data[[\"rallyid\", \"ServerWinsPoint\"]].drop_duplicates()\n\n# Add pred, probability columns\ntest_rally_outcomes[\"pred\"] = round(baseline_pred_proba)\ntest_rally_outcomes[\"prob\"] = baseline_pred_proba","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T01:58:42.402764Z","iopub.execute_input":"2025-02-09T01:58:42.403096Z","iopub.status.idle":"2025-02-09T01:58:42.424846Z","shell.execute_reply.started":"2025-02-09T01:58:42.403062Z","shell.execute_reply":"2025-02-09T01:58:42.423775Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Calculate Log Loss and Brier Score for points\nbaseline_outcome_lloss = log_loss(test_rally_outcomes[\"ServerWinsPoint\"], test_rally_outcomes[\"pred\"])\nbaseline_outcome_brier = brier_score_loss(test_rally_outcomes[\"ServerWinsPoint\"], test_rally_outcomes[\"prob\"])\n\nprint(f\"Baseline Outcome Model Log Loss: {baseline_outcome_lloss}\")\nprint(f\"Baseline Outcome Model Brier Score: {baseline_outcome_brier}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T01:58:42.426172Z","iopub.execute_input":"2025-02-09T01:58:42.426568Z","iopub.status.idle":"2025-02-09T01:58:42.452509Z","shell.execute_reply.started":"2025-02-09T01:58:42.426535Z","shell.execute_reply":"2025-02-09T01:58:42.451078Z"}},"outputs":[{"name":"stdout","text":"Baseline Outcome Model Log Loss: 15.249237972318793\nBaseline Outcome Model Brier Score: 0.24831784615384617\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# Calculate xSPW values, sums from taking outcome - probability\ntest_rally_outcomes[\"xSPW\"] = test_rally_outcomes[\"ServerWinsPoint\"] - test_rally_outcomes[\"prob\"]\nbaseline_xSPW = pd.merge(points_data[[\"rallyid\", \"server\"]], test_rally_outcomes).groupby(\"server\").xSPW.sum().reset_index()\nbaseline_xSPW","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T01:58:42.455818Z","iopub.execute_input":"2025-02-09T01:58:42.456226Z","iopub.status.idle":"2025-02-09T01:58:42.513458Z","shell.execute_reply.started":"2025-02-09T01:58:42.456196Z","shell.execute_reply":"2025-02-09T01:58:42.512201Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"     server   xSPW\n0  Djokovic -0.272\n1     Nadal -1.420","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>server</th>\n      <th>xSPW</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Djokovic</td>\n      <td>-0.272</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Nadal</td>\n      <td>-1.420</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":6},{"cell_type":"markdown","source":"# XGBoost","metadata":{}},{"cell_type":"code","source":"def objective(trial):\n    \"\"\"\n    Purpose: Create objective function to optimize model hyperparameters using Optuna.\n\n    Input(s):\n        trial (optuna.trial.Trial): A trial object that suggests hyperparameters.\n\n    Output(s):\n        cv_logloss (float): Negative mean log loss score from cross-validation.\n    \"\"\"\n\n    # Define the parameter space for XGBClassifier\n    param = {\n        \"verbosity\": 0,\n        \"objective\": \"reg:squarederror\",\n        \"booster\": \"gbtree\",\n        \"lambda\": trial.suggest_float(\"lambda\", 1e-8, 1.0, log=True),\n        \"alpha\": trial.suggest_float(\"alpha\", 1e-8, 1.0, log=True),\n        \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 1000),\n        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 9),\n        \"eta\": trial.suggest_float(\"eta\", 0.01, 0.3, log=True),\n        \"gamma\": trial.suggest_float(\"gamma\", 1e-8, 1.0, log=True),\n        \"grow_policy\": trial.suggest_categorical(\"grow_policy\", [\"depthwise\", \"lossguide\"]),\n        \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 10),\n    }\n    \n    # Train XGBClassifier with the defined parameters and evaluate using log loss\n    model = xgb.XGBClassifier(**param, eval_metric='logloss', use_label_encoder=True, enable_categorical=True)\n\n    # Set up KFold cross-validation\n    kf = KFold(n_splits=5, shuffle=True, random_state=909)\n    logloss_scores = cross_val_score(model, train_X, train_y, scoring='neg_log_loss', cv=kf, n_jobs=-1)\n\n    cv_logloss = -np.mean(logloss_scores)\n    return cv_logloss\n\n# Run the optimization study with direction to minimize the objective function\nstudy = optuna.create_study(direction=\"minimize\")\nstudy.optimize(objective, n_trials=50)\n\nprint(f\"Best Hyperparameters: {study.best_params}\")\nbest_params = study.best_params","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T01:58:42.515228Z","iopub.execute_input":"2025-02-09T01:58:42.515574Z","iopub.status.idle":"2025-02-09T01:59:24.096887Z","shell.execute_reply.started":"2025-02-09T01:58:42.515546Z","shell.execute_reply":"2025-02-09T01:59:24.095590Z"}},"outputs":[{"name":"stderr","text":"[I 2025-02-09 01:58:42,520] A new study created in memory with name: no-name-866154f0-30b4-4968-ab50-ebb06053e157\n[I 2025-02-09 01:58:45,715] Trial 0 finished with value: 0.9805666090301394 and parameters: {'lambda': 0.0480772079364898, 'alpha': 0.013727082109386599, 'n_estimators': 940, 'max_depth': 6, 'eta': 0.03076708038996653, 'gamma': 0.017129433651499104, 'grow_policy': 'depthwise', 'subsample': 0.8567963595984827, 'colsample_bytree': 0.5408508189495749, 'min_child_weight': 5}. Best is trial 0 with value: 0.9805666090301394.\n[I 2025-02-09 01:58:45,972] Trial 1 finished with value: 1.3154717542574048 and parameters: {'lambda': 3.423519869064144e-07, 'alpha': 1.827025518174209e-07, 'n_estimators': 203, 'max_depth': 4, 'eta': 0.15310520038232198, 'gamma': 1.1572646679781909e-06, 'grow_policy': 'depthwise', 'subsample': 0.749523865799189, 'colsample_bytree': 0.6243854435640737, 'min_child_weight': 6}. Best is trial 0 with value: 0.9805666090301394.\n[I 2025-02-09 01:58:46,427] Trial 2 finished with value: 0.6527308484747857 and parameters: {'lambda': 0.01716557933292679, 'alpha': 0.0005792607563933263, 'n_estimators': 371, 'max_depth': 8, 'eta': 0.012513487828933743, 'gamma': 0.45617458512358555, 'grow_policy': 'lossguide', 'subsample': 0.9190612383274293, 'colsample_bytree': 0.7398638361485013, 'min_child_weight': 10}. Best is trial 2 with value: 0.6527308484747857.\n[I 2025-02-09 01:58:47,867] Trial 3 finished with value: 1.0864977488362668 and parameters: {'lambda': 2.7847029977948616e-08, 'alpha': 0.00018878214891428978, 'n_estimators': 476, 'max_depth': 9, 'eta': 0.03885989201283477, 'gamma': 0.0010978944108071959, 'grow_policy': 'lossguide', 'subsample': 0.8002270506570464, 'colsample_bytree': 0.5311258211832846, 'min_child_weight': 6}. Best is trial 2 with value: 0.6527308484747857.\n[I 2025-02-09 01:58:48,226] Trial 4 finished with value: 0.6560130378808475 and parameters: {'lambda': 3.79443576558616e-07, 'alpha': 0.00014530736730739455, 'n_estimators': 533, 'max_depth': 8, 'eta': 0.025192215475736055, 'gamma': 0.5691024100034924, 'grow_policy': 'lossguide', 'subsample': 0.9617727688698938, 'colsample_bytree': 0.5770220297196256, 'min_child_weight': 5}. Best is trial 2 with value: 0.6527308484747857.\n[I 2025-02-09 01:58:48,697] Trial 5 finished with value: 0.7560942433006884 and parameters: {'lambda': 3.107042341063206e-08, 'alpha': 1.980045448164292e-08, 'n_estimators': 924, 'max_depth': 4, 'eta': 0.2510470578269015, 'gamma': 0.9051218474286884, 'grow_policy': 'depthwise', 'subsample': 0.5943080586913662, 'colsample_bytree': 0.9401708709686629, 'min_child_weight': 2}. Best is trial 2 with value: 0.6527308484747857.\n[I 2025-02-09 01:58:49,530] Trial 6 finished with value: 0.9552701162056678 and parameters: {'lambda': 3.698239111769224e-05, 'alpha': 4.530182725184134e-07, 'n_estimators': 741, 'max_depth': 9, 'eta': 0.05101578976443239, 'gamma': 0.048638472896237926, 'grow_policy': 'depthwise', 'subsample': 0.7260960673320707, 'colsample_bytree': 0.700873112796107, 'min_child_weight': 6}. Best is trial 2 with value: 0.6527308484747857.\n[I 2025-02-09 01:58:50,972] Trial 7 finished with value: 0.7919320362199223 and parameters: {'lambda': 8.621169130920555e-06, 'alpha': 0.01154063707617299, 'n_estimators': 631, 'max_depth': 6, 'eta': 0.01128541998784508, 'gamma': 3.283780721438627e-05, 'grow_policy': 'lossguide', 'subsample': 0.6964607815454741, 'colsample_bytree': 0.8512429582010255, 'min_child_weight': 7}. Best is trial 2 with value: 0.6527308484747857.\n[I 2025-02-09 01:58:51,590] Trial 8 finished with value: 1.8320110576735664 and parameters: {'lambda': 0.001747571915812213, 'alpha': 2.40966016429166e-07, 'n_estimators': 791, 'max_depth': 4, 'eta': 0.29120793138860673, 'gamma': 0.01073652186532315, 'grow_policy': 'lossguide', 'subsample': 0.7054597466130081, 'colsample_bytree': 0.6235056712836189, 'min_child_weight': 10}. Best is trial 2 with value: 0.6527308484747857.\n[I 2025-02-09 01:58:52,720] Trial 9 finished with value: 1.5358312041175384 and parameters: {'lambda': 4.529993977788865e-05, 'alpha': 0.0011923093226495016, 'n_estimators': 874, 'max_depth': 4, 'eta': 0.11655414645517984, 'gamma': 0.0015682630676729882, 'grow_policy': 'lossguide', 'subsample': 0.7316145632395867, 'colsample_bytree': 0.9683630930386313, 'min_child_weight': 8}. Best is trial 2 with value: 0.6527308484747857.\n[I 2025-02-09 01:58:53,328] Trial 10 finished with value: 0.6661713575714597 and parameters: {'lambda': 0.9449515283438978, 'alpha': 3.852374912117396e-06, 'n_estimators': 202, 'max_depth': 7, 'eta': 0.013874528314549961, 'gamma': 2.531622167601016e-08, 'grow_policy': 'lossguide', 'subsample': 0.9909924366320932, 'colsample_bytree': 0.7830307047371791, 'min_child_weight': 10}. Best is trial 2 with value: 0.6527308484747857.\n[I 2025-02-09 01:58:53,663] Trial 11 finished with value: 0.6585966662162734 and parameters: {'lambda': 0.002857590941845819, 'alpha': 3.219157533192954e-05, 'n_estimators': 448, 'max_depth': 8, 'eta': 0.0208158638433773, 'gamma': 0.9239746914691392, 'grow_policy': 'lossguide', 'subsample': 0.9857102072883379, 'colsample_bytree': 0.7231095173768689, 'min_child_weight': 3}. Best is trial 2 with value: 0.6527308484747857.\n[I 2025-02-09 01:58:54,300] Trial 12 finished with value: 0.6710510166237315 and parameters: {'lambda': 1.1710870619071033e-06, 'alpha': 0.44202929146561337, 'n_estimators': 392, 'max_depth': 7, 'eta': 0.021423359239910508, 'gamma': 0.1504216703169753, 'grow_policy': 'lossguide', 'subsample': 0.8816581868240592, 'colsample_bytree': 0.8359482872574335, 'min_child_weight': 4}. Best is trial 2 with value: 0.6527308484747857.\n[I 2025-02-09 01:58:56,514] Trial 13 finished with value: 0.7002943627163637 and parameters: {'lambda': 0.0009192492754328212, 'alpha': 5.380662330093179e-05, 'n_estimators': 320, 'max_depth': 8, 'eta': 0.01689162392053971, 'gamma': 7.334031485741581e-05, 'grow_policy': 'lossguide', 'subsample': 0.9090792876681427, 'colsample_bytree': 0.6119860730669819, 'min_child_weight': 1}. Best is trial 2 with value: 0.6527308484747857.\n[I 2025-02-09 01:58:58,172] Trial 14 finished with value: 0.7953277725117663 and parameters: {'lambda': 0.038047982668787526, 'alpha': 0.0020359268576268766, 'n_estimators': 593, 'max_depth': 8, 'eta': 0.010604123272236443, 'gamma': 0.0016290924143188246, 'grow_policy': 'lossguide', 'subsample': 0.9285187678397759, 'colsample_bytree': 0.6829291581317222, 'min_child_weight': 8}. Best is trial 2 with value: 0.6527308484747857.\n[I 2025-02-09 01:58:59,139] Trial 15 finished with value: 0.8970241972337958 and parameters: {'lambda': 6.885491964854305e-07, 'alpha': 0.6463360931849923, 'n_estimators': 291, 'max_depth': 7, 'eta': 0.07133180272225007, 'gamma': 3.545185423556137e-06, 'grow_policy': 'lossguide', 'subsample': 0.813621397375045, 'colsample_bytree': 0.7778350130172093, 'min_child_weight': 4}. Best is trial 2 with value: 0.6527308484747857.\n[I 2025-02-09 01:58:59,512] Trial 16 finished with value: 0.6795752930824146 and parameters: {'lambda': 0.4668573528606711, 'alpha': 0.00032531631750331257, 'n_estimators': 114, 'max_depth': 9, 'eta': 0.028010962396502755, 'gamma': 0.14853151422101732, 'grow_policy': 'lossguide', 'subsample': 0.5239571658186739, 'colsample_bytree': 0.5117266233703939, 'min_child_weight': 8}. Best is trial 2 with value: 0.6527308484747857.\n[I 2025-02-09 01:59:00,415] Trial 17 finished with value: 1.2944937987135408 and parameters: {'lambda': 0.00046417630870081053, 'alpha': 6.076879221545247e-06, 'n_estimators': 533, 'max_depth': 5, 'eta': 0.06914689858026318, 'gamma': 0.006149371040304762, 'grow_policy': 'lossguide', 'subsample': 0.9278202445484665, 'colsample_bytree': 0.8692380835161336, 'min_child_weight': 9}. Best is trial 2 with value: 0.6527308484747857.\n[I 2025-02-09 01:59:01,112] Trial 18 finished with value: 0.6683399121225077 and parameters: {'lambda': 0.04407638008510121, 'alpha': 0.05492912556031244, 'n_estimators': 675, 'max_depth': 6, 'eta': 0.01667477412743001, 'gamma': 0.1671887002649456, 'grow_policy': 'depthwise', 'subsample': 0.9624459246664465, 'colsample_bytree': 0.5953668831067678, 'min_child_weight': 4}. Best is trial 2 with value: 0.6527308484747857.\n[I 2025-02-09 01:59:02,581] Trial 19 finished with value: 0.8698552177686583 and parameters: {'lambda': 7.015092831853018e-06, 'alpha': 3.718590440961437e-06, 'n_estimators': 382, 'max_depth': 8, 'eta': 0.026874013530840634, 'gamma': 1.8407504976860638e-08, 'grow_policy': 'lossguide', 'subsample': 0.8506520230468486, 'colsample_bytree': 0.670186467883133, 'min_child_weight': 5}. Best is trial 2 with value: 0.6527308484747857.\n[I 2025-02-09 01:59:03,181] Trial 20 finished with value: 0.9064920636224816 and parameters: {'lambda': 0.010070332918420938, 'alpha': 0.0016054185537229388, 'n_estimators': 568, 'max_depth': 3, 'eta': 0.03727251517587937, 'gamma': 0.0002052121999162745, 'grow_policy': 'lossguide', 'subsample': 0.8022666811251211, 'colsample_bytree': 0.7493706334269968, 'min_child_weight': 7}. Best is trial 2 with value: 0.6527308484747857.\n[I 2025-02-09 01:59:03,752] Trial 21 finished with value: 0.6678513338776354 and parameters: {'lambda': 0.005056869552285058, 'alpha': 2.6509305746394846e-05, 'n_estimators': 455, 'max_depth': 8, 'eta': 0.01840499416129678, 'gamma': 0.2579867988222362, 'grow_policy': 'lossguide', 'subsample': 0.9918588459423655, 'colsample_bytree': 0.7288995208090036, 'min_child_weight': 3}. Best is trial 2 with value: 0.6527308484747857.\n[I 2025-02-09 01:59:04,169] Trial 22 finished with value: 0.6546439736832042 and parameters: {'lambda': 0.00019625478249639226, 'alpha': 1.5323236651849086e-05, 'n_estimators': 480, 'max_depth': 7, 'eta': 0.02263491924084337, 'gamma': 0.5727673122350171, 'grow_policy': 'lossguide', 'subsample': 0.9563574909612865, 'colsample_bytree': 0.8001891451045569, 'min_child_weight': 3}. Best is trial 2 with value: 0.6527308484747857.\n[I 2025-02-09 01:59:05,724] Trial 23 finished with value: 0.7054057985546205 and parameters: {'lambda': 0.00017403852430883068, 'alpha': 0.00034709349073637073, 'n_estimators': 517, 'max_depth': 7, 'eta': 0.01249985927552906, 'gamma': 0.04433570257362403, 'grow_policy': 'lossguide', 'subsample': 0.9199648271398385, 'colsample_bytree': 0.9105243838547867, 'min_child_weight': 1}. Best is trial 2 with value: 0.6527308484747857.\n[I 2025-02-09 01:59:06,078] Trial 24 finished with value: 0.6573274945571237 and parameters: {'lambda': 5.8354308363097656e-06, 'alpha': 1.141417057449606e-05, 'n_estimators': 325, 'max_depth': 7, 'eta': 0.02392911899739572, 'gamma': 0.5148723979400837, 'grow_policy': 'lossguide', 'subsample': 0.9602139493701045, 'colsample_bytree': 0.7977476868659206, 'min_child_weight': 3}. Best is trial 2 with value: 0.6527308484747857.\n[I 2025-02-09 01:59:07,025] Trial 25 finished with value: 0.8554001316118771 and parameters: {'lambda': 0.0002382332974939149, 'alpha': 1.543835785058129e-06, 'n_estimators': 693, 'max_depth': 9, 'eta': 0.041138342950821256, 'gamma': 0.044066887605156015, 'grow_policy': 'lossguide', 'subsample': 0.6399982133353916, 'colsample_bytree': 0.5683013522608962, 'min_child_weight': 2}. Best is trial 2 with value: 0.6527308484747857.\n[I 2025-02-09 01:59:07,706] Trial 26 finished with value: 0.7163427453035647 and parameters: {'lambda': 1.533925455032308e-07, 'alpha': 8.460244337482381e-05, 'n_estimators': 381, 'max_depth': 6, 'eta': 0.01522310302876325, 'gamma': 0.007584359491906717, 'grow_policy': 'depthwise', 'subsample': 0.8786283612089234, 'colsample_bytree': 0.6563070935602444, 'min_child_weight': 5}. Best is trial 2 with value: 0.6527308484747857.\n[I 2025-02-09 01:59:08,193] Trial 27 finished with value: 0.7038757685847629 and parameters: {'lambda': 0.16275036918369898, 'alpha': 0.009136001161351938, 'n_estimators': 263, 'max_depth': 8, 'eta': 0.05373624740849336, 'gamma': 0.053615220663488915, 'grow_policy': 'lossguide', 'subsample': 0.9538157674407148, 'colsample_bytree': 0.8223631724609844, 'min_child_weight': 2}. Best is trial 2 with value: 0.6527308484747857.\n[I 2025-02-09 01:59:09,560] Trial 28 finished with value: 1.0501606290050123 and parameters: {'lambda': 2.5812228045675266e-05, 'alpha': 0.0006897686160567208, 'n_estimators': 490, 'max_depth': 7, 'eta': 0.03310289004735283, 'gamma': 2.2556044830158674e-07, 'grow_policy': 'lossguide', 'subsample': 0.8474798824755537, 'colsample_bytree': 0.8858399054350207, 'min_child_weight': 7}. Best is trial 2 with value: 0.6527308484747857.\n[I 2025-02-09 01:59:10,398] Trial 29 finished with value: 0.9360374513438663 and parameters: {'lambda': 0.024656405845290042, 'alpha': 0.004328983176956964, 'n_estimators': 609, 'max_depth': 5, 'eta': 0.02859529318982947, 'gamma': 0.00042225789147273715, 'grow_policy': 'depthwise', 'subsample': 0.8882233267754143, 'colsample_bytree': 0.5671671042261869, 'min_child_weight': 5}. Best is trial 2 with value: 0.6527308484747857.\n[I 2025-02-09 01:59:12,021] Trial 30 finished with value: 0.7792837064728333 and parameters: {'lambda': 8.634317373448649e-08, 'alpha': 0.08338890816797642, 'n_estimators': 410, 'max_depth': 8, 'eta': 0.02112601043536346, 'gamma': 1.0190534231130144e-05, 'grow_policy': 'lossguide', 'subsample': 0.8303557178632521, 'colsample_bytree': 0.8101525935683948, 'min_child_weight': 4}. Best is trial 2 with value: 0.6527308484747857.\n[I 2025-02-09 01:59:12,400] Trial 31 finished with value: 0.657549660688698 and parameters: {'lambda': 2.664752020633388e-06, 'alpha': 2.2896385403641085e-05, 'n_estimators': 331, 'max_depth': 7, 'eta': 0.02415369809540967, 'gamma': 0.44785303661809656, 'grow_policy': 'lossguide', 'subsample': 0.9534016901081883, 'colsample_bytree': 0.7947751533025479, 'min_child_weight': 3}. Best is trial 2 with value: 0.6527308484747857.\n[I 2025-02-09 01:59:12,698] Trial 32 finished with value: 0.6569076067891902 and parameters: {'lambda': 4.362371811815373e-06, 'alpha': 1.195157013098087e-05, 'n_estimators': 219, 'max_depth': 7, 'eta': 0.013931821942172183, 'gamma': 0.8611945986327948, 'grow_policy': 'lossguide', 'subsample': 0.9589041359648762, 'colsample_bytree': 0.7650932157564809, 'min_child_weight': 2}. Best is trial 2 with value: 0.6527308484747857.\n[I 2025-02-09 01:59:13,404] Trial 33 finished with value: 0.6639439115702741 and parameters: {'lambda': 2.9482495711709524e-07, 'alpha': 0.0001679804342653496, 'n_estimators': 213, 'max_depth': 6, 'eta': 0.013232918403203968, 'gamma': 0.022425449526602022, 'grow_policy': 'lossguide', 'subsample': 0.9074393376801757, 'colsample_bytree': 0.7388136036362045, 'min_child_weight': 2}. Best is trial 2 with value: 0.6527308484747857.\n[I 2025-02-09 01:59:13,665] Trial 34 finished with value: 0.6576978390192142 and parameters: {'lambda': 7.5374237527376e-08, 'alpha': 5.112382533524168e-08, 'n_estimators': 127, 'max_depth': 9, 'eta': 0.01067775487816235, 'gamma': 0.9435311283969219, 'grow_policy': 'depthwise', 'subsample': 0.9455930468873285, 'colsample_bytree': 0.7663251974191922, 'min_child_weight': 1}. Best is trial 2 with value: 0.6527308484747857.\n[I 2025-02-09 01:59:14,237] Trial 35 finished with value: 0.6750109266104837 and parameters: {'lambda': 1.6063508720583257e-06, 'alpha': 1.0488134285181735e-06, 'n_estimators': 221, 'max_depth': 8, 'eta': 0.018144035758019136, 'gamma': 0.12858151240826132, 'grow_policy': 'lossguide', 'subsample': 0.9923210563500569, 'colsample_bytree': 0.648632494264381, 'min_child_weight': 6}. Best is trial 2 with value: 0.6527308484747857.\n[I 2025-02-09 01:59:15,206] Trial 36 finished with value: 0.7035713655718158 and parameters: {'lambda': 1.6557440027758863e-05, 'alpha': 0.0001032183769520093, 'n_estimators': 444, 'max_depth': 5, 'eta': 0.014000610503611432, 'gamma': 0.0038347877791259357, 'grow_policy': 'lossguide', 'subsample': 0.8740851103308945, 'colsample_bytree': 0.7005338896894159, 'min_child_weight': 2}. Best is trial 2 with value: 0.6527308484747857.\n[I 2025-02-09 01:59:15,845] Trial 37 finished with value: 0.6697315080376127 and parameters: {'lambda': 7.298400256250323e-05, 'alpha': 1.3919861268538979e-05, 'n_estimators': 994, 'max_depth': 7, 'eta': 0.04610186348016123, 'gamma': 0.3946814726347722, 'grow_policy': 'depthwise', 'subsample': 0.7749691243154049, 'colsample_bytree': 0.9175932573278109, 'min_child_weight': 6}. Best is trial 2 with value: 0.6527308484747857.\n[I 2025-02-09 01:59:16,272] Trial 38 finished with value: 0.958356293932203 and parameters: {'lambda': 1.7154348038435193e-08, 'alpha': 1.3379630282290437e-06, 'n_estimators': 180, 'max_depth': 9, 'eta': 0.10542455976482362, 'gamma': 0.022150751672463713, 'grow_policy': 'lossguide', 'subsample': 0.9063740132638892, 'colsample_bytree': 0.8579959934596108, 'min_child_weight': 5}. Best is trial 2 with value: 0.6527308484747857.\n[I 2025-02-09 01:59:16,703] Trial 39 finished with value: 0.7149739186011586 and parameters: {'lambda': 6.067560018020763e-07, 'alpha': 0.0004201088146065282, 'n_estimators': 267, 'max_depth': 6, 'eta': 0.03413585613148686, 'gamma': 0.09329790590579004, 'grow_policy': 'lossguide', 'subsample': 0.9682945896238248, 'colsample_bytree': 0.707695571428816, 'min_child_weight': 9}. Best is trial 2 with value: 0.6527308484747857.\n[I 2025-02-09 01:59:17,195] Trial 40 finished with value: 0.8560040375334952 and parameters: {'lambda': 0.1685177424863849, 'alpha': 3.499814928402194e-07, 'n_estimators': 809, 'max_depth': 8, 'eta': 0.19047078885424512, 'gamma': 0.27919297001801585, 'grow_policy': 'lossguide', 'subsample': 0.7713429845382923, 'colsample_bytree': 0.7544874602882807, 'min_child_weight': 3}. Best is trial 2 with value: 0.6527308484747857.\n[I 2025-02-09 01:59:17,491] Trial 41 finished with value: 0.658194245719694 and parameters: {'lambda': 5.589218323363003e-06, 'alpha': 8.298697876886885e-06, 'n_estimators': 343, 'max_depth': 7, 'eta': 0.023616488897769867, 'gamma': 0.9958114122403119, 'grow_policy': 'lossguide', 'subsample': 0.9384281238699105, 'colsample_bytree': 0.8024541090095352, 'min_child_weight': 3}. Best is trial 2 with value: 0.6527308484747857.\n[I 2025-02-09 01:59:18,102] Trial 42 finished with value: 0.6573410785876721 and parameters: {'lambda': 3.400559555638189e-06, 'alpha': 6.922107483904965e-05, 'n_estimators': 505, 'max_depth': 7, 'eta': 0.012361736462923267, 'gamma': 0.3983824931377742, 'grow_policy': 'lossguide', 'subsample': 0.9711446208800434, 'colsample_bytree': 0.9816092905837213, 'min_child_weight': 4}. Best is trial 2 with value: 0.6527308484747857.\n[I 2025-02-09 01:59:18,736] Trial 43 finished with value: 0.7097239267530092 and parameters: {'lambda': 1.2964675897200338e-05, 'alpha': 1.3718124994760193e-05, 'n_estimators': 162, 'max_depth': 7, 'eta': 0.018788540568205565, 'gamma': 0.07248387404970094, 'grow_policy': 'lossguide', 'subsample': 0.9975378206994183, 'colsample_bytree': 0.7743752107502849, 'min_child_weight': 2}. Best is trial 2 with value: 0.6527308484747857.\n[I 2025-02-09 01:59:19,443] Trial 44 finished with value: 0.6562207351364082 and parameters: {'lambda': 5.088363171901501e-05, 'alpha': 2.917171150847622e-06, 'n_estimators': 427, 'max_depth': 8, 'eta': 0.010032527252023811, 'gamma': 0.5275850023358326, 'grow_policy': 'lossguide', 'subsample': 0.6662660770966643, 'colsample_bytree': 0.839029184516015, 'min_child_weight': 3}. Best is trial 2 with value: 0.6527308484747857.\n[I 2025-02-09 01:59:21,037] Trial 45 finished with value: 0.7970244413262517 and parameters: {'lambda': 0.000977306881320666, 'alpha': 6.978145899440097e-08, 'n_estimators': 564, 'max_depth': 8, 'eta': 0.010122565585996337, 'gamma': 0.01450764516213676, 'grow_policy': 'lossguide', 'subsample': 0.6361952070764176, 'colsample_bytree': 0.8251469750870843, 'min_child_weight': 7}. Best is trial 2 with value: 0.6527308484747857.\n[I 2025-02-09 01:59:22,079] Trial 46 finished with value: 0.6686266075628905 and parameters: {'lambda': 0.00010421350424920795, 'alpha': 2.7785094945676655e-06, 'n_estimators': 420, 'max_depth': 9, 'eta': 0.011633610198241995, 'gamma': 0.24901202917646142, 'grow_policy': 'lossguide', 'subsample': 0.6732648141182628, 'colsample_bytree': 0.8452999356560553, 'min_child_weight': 1}. Best is trial 2 with value: 0.6527308484747857.\n[I 2025-02-09 01:59:22,412] Trial 47 finished with value: 0.6586170374134236 and parameters: {'lambda': 4.473717289523274e-05, 'alpha': 4.3913596996429435e-05, 'n_estimators': 365, 'max_depth': 8, 'eta': 0.015372024479669729, 'gamma': 0.9547348685603287, 'grow_policy': 'lossguide', 'subsample': 0.5271613704392542, 'colsample_bytree': 0.5379102362496897, 'min_child_weight': 9}. Best is trial 2 with value: 0.6527308484747857.\n[I 2025-02-09 01:59:23,381] Trial 48 finished with value: 0.7200987438638764 and parameters: {'lambda': 0.0003279349526832573, 'alpha': 7.100617262995276e-07, 'n_estimators': 455, 'max_depth': 8, 'eta': 0.013998685478783943, 'gamma': 0.11052185028063412, 'grow_policy': 'depthwise', 'subsample': 0.6969114431244087, 'colsample_bytree': 0.890152806425998, 'min_child_weight': 4}. Best is trial 2 with value: 0.6527308484747857.\n[I 2025-02-09 01:59:24,090] Trial 49 finished with value: 0.7078443205386099 and parameters: {'lambda': 1.151714672468697e-06, 'alpha': 0.0001545161680785511, 'n_estimators': 253, 'max_depth': 9, 'eta': 0.01577523419440438, 'gamma': 0.002821429465833467, 'grow_policy': 'lossguide', 'subsample': 0.5538348619187996, 'colsample_bytree': 0.9541708818268133, 'min_child_weight': 10}. Best is trial 2 with value: 0.6527308484747857.\n","output_type":"stream"},{"name":"stdout","text":"Best Hyperparameters: {'lambda': 0.01716557933292679, 'alpha': 0.0005792607563933263, 'n_estimators': 371, 'max_depth': 8, 'eta': 0.012513487828933743, 'gamma': 0.45617458512358555, 'grow_policy': 'lossguide', 'subsample': 0.9190612383274293, 'colsample_bytree': 0.7398638361485013, 'min_child_weight': 10}\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# Train final model with best params\nxgb_model = xgb.XGBClassifier(**best_params, use_label_encoder = True, enable_categorical = True)\nxgb_model.fit(train_X, train_y)\n\nplot_importance(xgb_model, importance_type='weight')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T01:59:24.098134Z","iopub.execute_input":"2025-02-09T01:59:24.098519Z","iopub.status.idle":"2025-02-09T01:59:24.684700Z","shell.execute_reply.started":"2025-02-09T01:59:24.098484Z","shell.execute_reply":"2025-02-09T01:59:24.683398Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"<Axes: title={'center': 'Feature importance'}, xlabel='F score', ylabel='Features'>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"# Repeat process for XGBoost, predicting only with final rally\ntest_data_final_stroke = test_data.groupby(\"rallyid\").strokeid.max().reset_index()\ntest_X_xgb = pd.merge(test_data, test_data_final_stroke)[xgb_model_data_cols].astype({\"stroke\":'category', \"type_of_shot\":'category'}) \ntest_y_xgb = test_data[[\"rallyid\", \"ServerWinsPoint\"]].drop_duplicates().reset_index(drop = True)\n\ntest_y_outcomes = test_data.ServerWinsPoint\npred_y = xgb_model.predict(test_X_xgb)\npred_proba_y = xgb_model.predict_proba(test_X_xgb)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T01:59:24.686120Z","iopub.execute_input":"2025-02-09T01:59:24.686462Z","iopub.status.idle":"2025-02-09T01:59:24.718610Z","shell.execute_reply.started":"2025-02-09T01:59:24.686435Z","shell.execute_reply":"2025-02-09T01:59:24.717449Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# Caluclate Log Loss and Brier Score\nxgboost_lloss = log_loss(test_y_xgb.ServerWinsPoint, pred_y)\nxgboost_brier = brier_score_loss(test_y_xgb.ServerWinsPoint, pred_proba_y[:, 1])\n\nprint(f\"XGBoost Event Model Log Loss: {xgboost_lloss}\")\nprint(f\"XGBoost Event Model Brier Score: {xgboost_brier}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T01:59:24.719332Z","iopub.execute_input":"2025-02-09T01:59:24.719607Z","iopub.status.idle":"2025-02-09T01:59:24.748442Z","shell.execute_reply.started":"2025-02-09T01:59:24.719583Z","shell.execute_reply":"2025-02-09T01:59:24.747101Z"}},"outputs":[{"name":"stdout","text":"XGBoost Event Model Log Loss: 13.862943611198906\nXGBoost Event Model Brier Score: 0.24270232940998177\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# Calculate xSPW values, sums\ntest_y_xgb[\"prob\"] = pred_proba_y[:, 1]\ntest_y_xgb[\"xSPW\"] = test_y_xgb[\"ServerWinsPoint\"] - test_y_xgb[\"prob\"]\n\nxgb_xSPW = pd.merge(points_data[[\"rallyid\", \"server\"]], test_y_xgb).groupby(\"server\").xSPW.sum().reset_index()\nxgb_xSPW","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T01:59:24.749802Z","iopub.execute_input":"2025-02-09T01:59:24.750307Z","iopub.status.idle":"2025-02-09T01:59:24.782635Z","shell.execute_reply.started":"2025-02-09T01:59:24.750263Z","shell.execute_reply":"2025-02-09T01:59:24.781473Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"     server      xSPW\n0  Djokovic  0.797742\n1     Nadal -1.133754","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>server</th>\n      <th>xSPW</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Djokovic</td>\n      <td>0.797742</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Nadal</td>\n      <td>-1.133754</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":11},{"cell_type":"markdown","source":"# Neural Nets","metadata":{}},{"cell_type":"code","source":"# Set X and y columns\nnnet_model_data_cols = [\"rallyid\", \"strokeid\", 'stroke', 'type_of_shot', 'time_diff','server_x', 'server_y', 'receiver_x', 'receiver_y',\n                   'server_distance_from_baseline', 'receiver_distance_from_baseline']\n\ntrain_X = train_data[nnet_model_data_cols].astype({\"stroke\":'category', \"type_of_shot\":'category'}) \ntest_X = test_data[nnet_model_data_cols].astype({\"stroke\":'category', \"type_of_shot\":'category'}) \n\ntrain_y = train_data[[\"rallyid\", \"ServerWinsPoint\"]].drop_duplicates().reset_index(drop = True)\ntest_y = test_data[[\"rallyid\", \"ServerWinsPoint\"]].drop_duplicates().reset_index(drop = True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T01:59:24.783759Z","iopub.execute_input":"2025-02-09T01:59:24.784107Z","iopub.status.idle":"2025-02-09T01:59:24.816993Z","shell.execute_reply.started":"2025-02-09T01:59:24.784078Z","shell.execute_reply":"2025-02-09T01:59:24.815776Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"def perform_ohc_transformation(data, cols_to_encode, one_hot_encoder = None):\n    \"\"\"\n    Purpose: With raw dataset, transform input columns with one-hot encoder\n\n    Input(s): \n        data (pd.DataFrame): Raw dataset\n        cols_to_encode (list): contains names of column in input\n        one_hot_encoder (NoneType or Sklearn object): default None, creates or uses preexisting one-hot encoder object\n\n    Output(s):\n        preprocessed_data (NumPy array): Dataset with one-hot encoded columns\n        one_hot_encoder (Sklearn object): Newly created or existing OHC object\n    \"\"\"\n\n    # Check if OHC object exists\n    if one_hot_encoder is None:\n        # Initialize OHC Object\n        one_hot_encoder = OneHotEncoder(sparse=False, drop = \"first\", handle_unknown = \"ignore\")\n\n        # Fit the encoder to the specified columns\n        encoded_columns = one_hot_encoder.fit_transform(data[cols_to_encode])\n\n    else:\n        # Fit the encoder to the specified columns\n        encoded_columns = one_hot_encoder.transform(data[cols_to_encode])\n        \n    # Convert encoded columns to DataFrame\n    encoded_cols = pd.DataFrame(encoded_columns, columns=one_hot_encoder.get_feature_names_out(cols_to_encode))\n        \n    # Concatenate encoded columns with the original DataFrame\n    preprocessed_data = pd.concat([data.drop(columns=cols_to_encode), encoded_cols], axis=1)\n    \n    return(preprocessed_data, one_hot_encoder)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T01:59:24.818078Z","iopub.execute_input":"2025-02-09T01:59:24.818469Z","iopub.status.idle":"2025-02-09T01:59:24.826011Z","shell.execute_reply.started":"2025-02-09T01:59:24.818424Z","shell.execute_reply":"2025-02-09T01:59:24.824539Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"def prepare_nnet_data(x_train, y_train, ohc_cols, fit_ohc=None):\n    \"\"\"\n    Purpose: Prepare the data for training an LSTM model via OHC and segmenting data into lists of arrays\n\n    Input(s):\n        x_train (pd.DataFrame): Contains training data\n        y_train (pd.DataFrame): Contains training data labels\n        ohc_cols (list): List of columns to be one-hot encoded\n        fit_ohc (OneHotEncoder): Pre-fitted OneHotEncoder. Default None, creates a new encoder if None\n\n    Output(s):\n        tuple: A tuple containing preprocessed data with padding (X, y), plus fitted OneHotEncoder.\n    \"\"\"\n    \n    # Perform one-hot encoding\n    if fit_ohc is None:\n        X_tr, encoder = perform_ohc_transformation(x_train, ohc_cols)\n    else:\n        X_tr, encoder = perform_ohc_transformation(x_train, ohc_cols, one_hot_encoder=fit_ohc)\n\n\n    # Prepare the data for LSTM\n    X = []\n    y = []\n    rallies = X_tr[\"rallyid\"].unique()\n\n    # Iterating through unique rallies\n    for rally in rallies:\n        # Select all events\n        event_data = X_tr[X_tr[\"rallyid\"] == rally]\n        outcome = y_train[y_train[\"rallyid\"] == rally]\n\n        # Convert data into own array, add to list of data\n        X.append(event_data.drop([\"rallyid\", \"strokeid\"], axis=1).values)\n        y.append(outcome[\"ServerWinsPoint\"].values[0])\n\n    y = np.array(y)\n    return (X, y, encoder)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T01:59:24.827055Z","iopub.execute_input":"2025-02-09T01:59:24.827348Z","iopub.status.idle":"2025-02-09T01:59:24.853116Z","shell.execute_reply.started":"2025-02-09T01:59:24.827325Z","shell.execute_reply":"2025-02-09T01:59:24.851505Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# Specify columns to be encoded\ncolumns_to_encode = ['type_of_shot', 'stroke']\nX_nnet, y_nnet, ohc = prepare_nnet_data(train_X, train_y, columns_to_encode)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T01:59:24.854602Z","iopub.execute_input":"2025-02-09T01:59:24.855085Z","iopub.status.idle":"2025-02-09T01:59:24.996598Z","shell.execute_reply.started":"2025-02-09T01:59:24.855048Z","shell.execute_reply":"2025-02-09T01:59:24.994884Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"# Define number of timestamps, features to use in LSTM model\nmax_strokes_per_rally = train_X.groupby(\"rallyid\").strokeid.count().reset_index().strokeid.max()\nnum_features = len(X_nnet[0][0])\n\n# Pad preprocessed data to go up to max number of timestamps \nX_nnet_padded = pad_sequences(X_nnet, padding = 'post', dtype = 'float32', value = -100, maxlen = max_strokes_per_rally)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T01:59:24.998009Z","iopub.execute_input":"2025-02-09T01:59:24.998442Z","iopub.status.idle":"2025-02-09T01:59:25.009184Z","shell.execute_reply.started":"2025-02-09T01:59:24.998398Z","shell.execute_reply":"2025-02-09T01:59:25.008115Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# Perform 5-fold cross-validation\nkf = KFold(n_splits=5, shuffle=True, random_state=909)\nfold = 1\n\nlog_loss_scores = []\n\n# Iterating through each fold\nfor train_index, test_index in kf.split(X_nnet_padded):\n    print(f'Fold {fold}')\n    X_train, X_test = X_nnet_padded[train_index], X_nnet_padded[test_index]\n    y_train, y_test = y_nnet[train_index], y_nnet[test_index]\n\n    # Defining the LSTM Sequential model (simple, heavily regularized)\n    model = Sequential()\n    model.add(LSTM(5, activation='relu', recurrent_dropout=0.1, \n              kernel_regularizer=l2(0.01), input_shape = (max_strokes_per_rally, num_features)))\n    model.add(Dense(1, activation='sigmoid', kernel_regularizer=l2(0.01)))\n    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\n    # Early stopping callback\n    early_stopping = EarlyStopping(monitor='loss', patience=5, min_delta = 0.5,restore_best_weights=True)\n    \n    # Train the model with callback\n    model.fit(X_train, y_train, epochs=25, batch_size=16, callbacks=[early_stopping])\n\n    # Evaluate the model\n    loss, accuracy = model.evaluate(X_test, y_test)\n    print(f'Test Accuracy for fold {fold}: {accuracy * 100:.2f}%')\n    \n    # Predict the outcome\n    y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n    print(f'Predicted outcomes for fold {fold}: {y_pred.flatten()}')\n\n    log_loss_scores.append(loss)\n    fold += 1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T01:59:25.010453Z","iopub.execute_input":"2025-02-09T01:59:25.010881Z","iopub.status.idle":"2025-02-09T01:59:42.611953Z","shell.execute_reply.started":"2025-02-09T01:59:25.010843Z","shell.execute_reply":"2025-02-09T01:59:42.610738Z"}},"outputs":[{"name":"stdout","text":"Fold 1\nEpoch 1/25\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.4236 - loss: 2.2916\nEpoch 2/25\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6562 - loss: 0.8886\nEpoch 3/25\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6562 - loss: 0.8846\nEpoch 4/25\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6562 - loss: 0.9076 \nEpoch 5/25\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6562 - loss: 0.8750 \nEpoch 6/25\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6562 - loss: 0.8705 \nEpoch 7/25\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6562 - loss: 0.8661 \n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305ms/step - accuracy: 0.8095 - loss: 0.8782\nTest Accuracy for fold 1: 80.95%\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step\nPredicted outcomes for fold 1: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\nFold 2\nEpoch 1/25\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6232 - loss: 0.8933\nEpoch 2/25\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6710 - loss: 0.8849 \nEpoch 3/25\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6710 - loss: 0.8769 \nEpoch 4/25\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6710 - loss: 0.8692\nEpoch 5/25\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6710 - loss: 0.8618 \nEpoch 6/25\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6710 - loss: 0.8547 \n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301ms/step - accuracy: 0.6667 - loss: 0.8539\nTest Accuracy for fold 2: 66.67%\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step\nPredicted outcomes for fold 2: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\nFold 3\nEpoch 1/25\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6907 - loss: 0.8690\nEpoch 2/25\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6907 - loss: 0.8472\nEpoch 3/25\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6907 - loss: 0.8387\nEpoch 4/25\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6907 - loss: 0.8253 \nEpoch 5/25\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6907 - loss: 0.8161\nEpoch 6/25\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6907 - loss: 0.8102\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 322ms/step - accuracy: 0.7000 - loss: 0.8493\nTest Accuracy for fold 3: 70.00%\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step\nPredicted outcomes for fold 3: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\nFold 4\nEpoch 1/25\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6739 - loss: 46.5484\nEpoch 2/25\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6401 - loss: 48.7878 \nEpoch 3/25\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6858 - loss: 39.2207 \nEpoch 4/25\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6880 - loss: 40.4919 \nEpoch 5/25\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6909 - loss: 38.9602 \nEpoch 6/25\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6514 - loss: 38.6452 \nEpoch 7/25\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6611 - loss: 35.3386 \nEpoch 8/25\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6231 - loss: 43.3892 \nEpoch 9/25\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6365 - loss: 35.1404\nEpoch 10/25\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6438 - loss: 23.6074\nEpoch 11/25\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6459 - loss: 1.3674 \nEpoch 12/25\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6623 - loss: 1.4216 \nEpoch 13/25\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6623 - loss: 1.3438 \nEpoch 14/25\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6623 - loss: 1.2398 \nEpoch 15/25\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6623 - loss: 1.1502 \nEpoch 16/25\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6623 - loss: 1.0613 \n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333ms/step - accuracy: 0.7500 - loss: 1.4615\nTest Accuracy for fold 4: 75.00%\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step\nPredicted outcomes for fold 4: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\nFold 5\nEpoch 1/25\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5600 - loss: 0.8809\nEpoch 2/25\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7271 - loss: 0.8721 \nEpoch 3/25\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7271 - loss: 0.8629 \nEpoch 4/25\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7271 - loss: 0.8543 \nEpoch 5/25\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7271 - loss: 0.8459 \nEpoch 6/25\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7271 - loss: 0.8378 \n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301ms/step - accuracy: 0.5000 - loss: 0.8768\nTest Accuracy for fold 5: 50.00%\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step\nPredicted outcomes for fold 5: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"# Log-Loss as mean across all folds\nprint(f\"LSTM Model, Mean CV Log-Loss: {np.mean(log_loss_scores)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T01:59:42.613617Z","iopub.execute_input":"2025-02-09T01:59:42.614049Z","iopub.status.idle":"2025-02-09T01:59:42.620084Z","shell.execute_reply.started":"2025-02-09T01:59:42.614008Z","shell.execute_reply":"2025-02-09T01:59:42.618674Z"}},"outputs":[{"name":"stdout","text":"LSTM Model, Mean CV Log-Loss: 0.9839289426803589\n","output_type":"stream"}],"execution_count":18},{"cell_type":"markdown","source":"# Train Final Model, Get Predictions","metadata":{}},{"cell_type":"code","source":"# Retrain model using all sequences\nmodel = Sequential()\nmodel.add(LSTM(5, activation='relu', recurrent_dropout=0.1, \n              kernel_regularizer=l2(0.01), input_shape = (max_strokes_per_rally, num_features)))\nmodel.add(Dense(1, activation='sigmoid', kernel_regularizer=l2(0.01)))\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\nearly_stopping = EarlyStopping(monitor='loss', patience=5, min_delta = 0.5, restore_best_weights=True)\n    \nmodel.fit(X_nnet_padded, y_nnet, epochs=25, batch_size=16, callbacks=[early_stopping])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T02:00:07.085636Z","iopub.execute_input":"2025-02-09T02:00:07.086014Z","iopub.status.idle":"2025-02-09T02:00:10.292386Z","shell.execute_reply.started":"2025-02-09T02:00:07.085985Z","shell.execute_reply":"2025-02-09T02:00:10.290847Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/25\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.7622 - loss: 0.8842\nEpoch 2/25\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7622 - loss: 0.8706\nEpoch 3/25\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7622 - loss: 0.8630\nEpoch 4/25\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7622 - loss: 0.8525\nEpoch 5/25\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7622 - loss: 0.8352\nEpoch 6/25\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7622 - loss: 0.8196\n","output_type":"stream"},{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7cea8db55ae0>"},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"# Preprocess test set\ntest_X_nnet, test_y_nnet, ohc = prepare_nnet_data(test_X, test_y, columns_to_encode, ohc)\ntest_X_nnet_padded = pad_sequences(test_X_nnet, padding = 'post', dtype = 'float32', value = -100, maxlen = max_strokes_per_rally)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T02:00:14.342912Z","iopub.execute_input":"2025-02-09T02:00:14.343412Z","iopub.status.idle":"2025-02-09T02:00:14.398611Z","shell.execute_reply.started":"2025-02-09T02:00:14.343368Z","shell.execute_reply":"2025-02-09T02:00:14.397306Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"# Calculate test set preds, Log Loss, Brier Score\ntest_y[\"prob\"] = model.predict(test_X_nnet_padded)\ntest_y[\"xSPW\"] = test_y.ServerWinsPoint - test_y.prob\n\nprint(f\"LSTM Model Log-Loss: {log_loss(test_y['ServerWinsPoint'], test_y['prob'])}\")\nprint(f\"LSTM Model Brier Score: {brier_score_loss(test_y['ServerWinsPoint'], test_y['prob'])}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T02:00:16.221538Z","iopub.execute_input":"2025-02-09T02:00:16.222031Z","iopub.status.idle":"2025-02-09T02:00:16.496578Z","shell.execute_reply.started":"2025-02-09T02:00:16.221987Z","shell.execute_reply":"2025-02-09T02:00:16.495251Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step\nLSTM Model Log-Loss: 0.6897888998977844\nLSTM Model Brier Score: 0.2483212559170123\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"# Recalculate xSPW values, sums\nplayer_xSPW = pd.merge(points_data[[\"rallyid\", \"server\"]], test_y)\nplayer_summary_final_games = player_xSPW.groupby(\"server\").xSPW.sum().reset_index()\nplayer_summary_final_games","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T02:00:18.317139Z","iopub.execute_input":"2025-02-09T02:00:18.317535Z","iopub.status.idle":"2025-02-09T02:00:18.334411Z","shell.execute_reply.started":"2025-02-09T02:00:18.317503Z","shell.execute_reply":"2025-02-09T02:00:18.333068Z"}},"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"     server      xSPW\n0  Djokovic  1.889598\n1     Nadal -0.045445","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>server</th>\n      <th>xSPW</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Djokovic</td>\n      <td>1.889598</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Nadal</td>\n      <td>-0.045445</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"# Save model\nmodel.save(output_path + 'xspw_prototype.h5')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T02:00:33.216452Z","iopub.execute_input":"2025-02-09T02:00:33.216829Z","iopub.status.idle":"2025-02-09T02:00:33.251558Z","shell.execute_reply.started":"2025-02-09T02:00:33.216797Z","shell.execute_reply":"2025-02-09T02:00:33.250341Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"def create_cumulative_sequences(data, length, n, m):\n    \"\"\"\n    Purpose: Create cumulative sequences of event data with padding\n\n    Input(s):\n        data (list): A list of sequences containing event data\n        length (int): The maximum length of the sequences after padding\n        n (int): The number of sequences\n        m (int): The number of features in each sequence\n\n    Output(s):\n        events_component (np.ndarray): An array of padded cumulative event sequences with the shape (n, length, m).\n    \"\"\"\n    \n    # Initialize list to hold cumulative event sequences\n    event_components = []\n\n    # Iterate through each sequence in the data\n    for ind in range(len(data)):\n        for event_ind in range(len(data[ind])):\n            # Create a cumulative sequence up to the current event\n            sequence = [data[ind][:event_ind + 1]]\n            \n            # Pad the sequence to the specified length\n            padded_sequence = pad_sequences(sequence, padding='post', dtype='float32', value=-100, maxlen=length)\n            event_components.append(padded_sequence)\n    \n    # Reshape the event components to the desired shape\n    event_components = np.array(event_components).reshape(n, length, m)\n\n    return event_components","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T02:00:36.389815Z","iopub.execute_input":"2025-02-09T02:00:36.390300Z","iopub.status.idle":"2025-02-09T02:00:36.400267Z","shell.execute_reply.started":"2025-02-09T02:00:36.390258Z","shell.execute_reply":"2025-02-09T02:00:36.398697Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"# Convert test set into list of cumulative padded sequences for each event\nnum_samples = test_X.shape[0]\nn_features = test_X_nnet[0].shape[1]\n\nX_test_sequential = create_cumulative_sequences(test_X_nnet, max_strokes_per_rally, num_samples, n_features)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T02:00:41.009584Z","iopub.execute_input":"2025-02-09T02:00:41.010081Z","iopub.status.idle":"2025-02-09T02:00:41.021039Z","shell.execute_reply.started":"2025-02-09T02:00:41.010037Z","shell.execute_reply":"2025-02-09T02:00:41.019732Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"# For each sequence, predict probabilty of server winning at each event\npredict_df = test_X.copy()\npredict_df[\"prob\"] = model.predict(X_test_sequential)\n\npredict_df.to_csv(\"event_predictions.csv\", index = False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T02:00:41.974447Z","iopub.execute_input":"2025-02-09T02:00:41.974842Z","iopub.status.idle":"2025-02-09T02:00:42.268278Z","shell.execute_reply.started":"2025-02-09T02:00:41.974811Z","shell.execute_reply":"2025-02-09T02:00:42.267088Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step  \n","output_type":"stream"}],"execution_count":26}]}